{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "from model import OU_PINN\n",
        "from data_generation import generate_training_data\n",
        "from training import train\n",
        "from config import device, k, theta, sigma, lambda_jump, jump_std, LEARNING_RATE\n",
        "\n",
        "# --- Configuration for the architecture search ---\n",
        "\n",
        "# 1. Define the architectures to test: (hidden_layers, neurons_per_layer)\n",
        "ARCHITECTURES_TO_TEST = [\n",
        "    (2, 20),   # Small\n",
        "    (3, 20),\n",
        "    (4, 20),\n",
        "    (3, 30),   # Medium\n",
        "    (4, 30),\n",
        "    (6, 30),   # Larger (like the current default)\n",
        "    (4, 50),   # Wider\n",
        "    (8, 30)    # Deeper\n",
        "]\n",
        "\n",
        "# 2. Number of epochs to train each architecture\n",
        "# This should be low enough for a quick test.\n",
        "EPOCHS_PER_RUN = 2000 # You can adjust this value\n",
        "\n",
        "# --- Main execution ---\n",
        "\n",
        "def find_best_architecture():\n",
        "    \"\"\"\n",
        "    Trains multiple network architectures and reports the one with the lowest final loss.\n",
        "    \"\"\"\n",
        "    print(\"Starting architecture search...\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Each architecture will be trained for {EPOCHS_PER_RUN} epochs.\")\n",
        "\n",
        "    # Generate a single, consistent dataset for all runs\n",
        "    print(\"\\\\nGenerating a consistent training dataset...\")\n",
        "    X_r, X_data, u_data = generate_training_data()\n",
        "    print(\"Dataset generated successfully.\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Loop over all defined architectures\n",
        "    for i, (layers, neurons) in enumerate(ARCHITECTURES_TO_TEST):\n",
        "        print(\"\\\\n\" + \"=\" * 60)\n",
        "        print(f\"Testing architecture {i+1}/{len(ARCHITECTURES_TO_TEST)}: {layers} hidden layers, {neurons} neurons/layer\")\n",
        "\n",
        "        # Initialize the model with the current architecture\n",
        "        model = OU_PINN(hidden_layers=layers, neurons_per_layer=neurons).to(device)\n",
        "\n",
        "        # Display model parameters\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        print(f\"Total model parameters: {total_params:,}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train the model\n",
        "        # Note: The 'train' function prints its own progress.\n",
        "        training_history = train(\n",
        "            model, X_r, X_data, u_data,\n",
        "            k, theta, sigma, lambda_jump, jump_std,\n",
        "            epochs=EPOCHS_PER_RUN, lr=LEARNING_RATE\n",
        "        )\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_duration = end_time - start_time\n",
        "\n",
        "        # Get the final loss from the training history\n",
        "        final_loss = training_history[-1]['total_loss']\n",
        "        print(f\"Architecture training completed in {training_duration:.2f}s. Final loss: {final_loss:.6f}\")\n",
        "\n",
        "        # Store results for this architecture\n",
        "        results.append({\n",
        "            'layers': layers,\n",
        "            'neurons': neurons,\n",
        "            'params': total_params,\n",
        "            'final_loss': final_loss,\n",
        "            'duration': training_duration\n",
        "        })\n",
        "\n",
        "    # --- Report the final results ---\n",
        "    print(\"\\\\n\" + \"=\" * 60)\n",
        "    print(\"Architecture Search Complete. Results:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Layers':<10} {'Neurons':<10} {'Parameters':<15} {'Final Loss':<15} {'Duration (s)':<15}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Sort results by final loss to find the best\n",
        "    sorted_results = sorted(results, key=lambda x: x['final_loss'])\n",
        "\n",
        "    for res in sorted_results:\n",
        "        params_str = f\"{res['params']:,}\"\n",
        "        loss_str = f\"{res['final_loss']:.6f}\"\n",
        "        duration_str = f\"{res['duration']:.2f}\"\n",
        "        print(f\"{res['layers']:<10} {res['neurons']:<10} {params_str:<15} {loss_str:<15} {duration_str}\")\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    best_architecture = sorted_results[0]\n",
        "    print(f\"\\\\nBest performing architecture found:\")\n",
        "    print(f\"  - Layers: {best_architecture['layers']}\")\n",
        "    print(f\"  - Neurons per layer: {best_architecture['neurons']}\")\n",
        "    print(f\"  - Final Loss: {best_architecture['final_loss']:.6f}\")\n",
        "\n",
        "find_best_architecture() "
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
